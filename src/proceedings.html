<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>启元实验室 - 论文集</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Pacifico&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="css/global.css">
    <link rel="stylesheet" href="css/proceedings.css">
    <script src="js/proceedings.js"></script>
    <script src="js/tailwind-config.js"></script>
    <!-- 添加mdjs文件 -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
</head>

<body class="bg-gray-50">
    {% include "headernjk.njk" %}
    <!-- <header class="fixed top-0 left-0 right-0 bg-white shadow-sm z-50">
        <div class="max-w-7xl mx-auto px-4">
            <div class="flex items-center justify-between h-16">
                <div class="flex items-center">
                    <a href="#" class="text-2xl font-['Pacifico'] text-primary">logo</a>
                </div>
                <nav class="flex space-x-8">
                    <a href="index" class="text-gray-700 hover:text-primary px-3 py-2 text-sm font-medium">首页</a>
                    <a href="news" class="text-gray-700 hover:text-primary px-3 py-2 text-sm font-medium">新闻</a>
                    <a href="#" class="text-[#0066CC] px-3 py-2 text-sm font-medium">论文集</a>
                    <a href="teamMember" class="text-gray-700 hover:text-primary px-3 py-2 text-sm font-medium">成员</a>
                    <a href="collaboration"
                        class="text-gray-700 hover:text-primary px-3 py-2 text-sm font-medium">合作</a>
                </nav>
            </div>
        </div>
    </header> -->
    <main class="max-w-7xl mx-auto px-4 pt-24 pb-12">
        <div class="mb-8">
            <h1 class="text-3xl font-bold text-gray-900">论文集</h1>
            <p class="mt-2 text-gray-600">探索前沿科技研究成果</p>
        </div>
        <div class="grid grid-cols-3 gap-6">
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper1')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderT.jpg" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">VToT：通过LLMs使用思维树提示自动生成Verilog</h3>
                    <p class="text-gray-600 text-sm mb-4">本文被CCFB类会议，2025'DATE（Design, Automation and Test in Europe。
                        Conference）</p>
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>周英杰...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2024-9-23</span>
                    </div>
                </div>
            </div>
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper2')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderF.png" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">LintLLM：基于大语言模型的开源Verilog Linting框架
                    </h3>
                    <p class="text-gray-600 text-sm mb-4">首次使用LLM完成Verilog代码Linting任务，提升缺陷检测率的同时显著降低使用成本。
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>方志刚...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2025-2-15</span>
                    </div>
                </div>
            </div>
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper3')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderX.png" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">基于 LLM 的处理器验证：神经形态处理器案例研究</h3>
                    <p class="text-gray-600 text-sm mb-4">本文被2024年设计、自动化与测试欧洲会议（DATE）录用。</p>
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>肖朝...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2024-03-27</span>
                    </div>
                </div>
            </div>
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper4')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderD.png" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">VToT：通过LLMs使用思维树提示自动生成Verilog</h3>
                    <p class="text-gray-600 text-sm mb-4">本文被IEEE第42届国际计算机设计会议（ICCD
                        2024）收录，会议于2024年在意大利米兰举行。ICCD是计算机体系结构与设计领域的权威会议，CCF推荐为B类会议。相关代码与提示库已开源。</p>
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>邓一飞...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2024-10-24</span>
                    </div>
                </div>
            </div>
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper5')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderWW.png" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">PerturbGen：一个基于种群扰动的硬件测试生成框架</h3>
                    <p class="text-gray-600 text-sm mb-4">本文提出了一个种群扰动的硬件测试生成框架PerturbGen，显著提升处理器验证中的覆盖率。</p>
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>王静凯...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2024-11-20</span>
                    </div>
                </div>
            </div>
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper6')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderL.png" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">针对可配置神经形态处理器的硬件与算法协同设计</h3>
                    <p class="text-gray-600 text-sm mb-4">本文被CCFB类会议，2024'ICCD（IEEE International Conference on Computer
                        Design）接收录用为Short Paper。</p>
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>李媛...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2024-11-8</span>
                    </div>
                </div>
            </div>
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper7')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderTwoX.jpg" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">大规模脉冲卷积神经网络到资源受限类脑处理器的分层映射</h3>
                    <p class="text-gray-600 text-sm mb-4">本文被CCF A类期刊，IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems （缩写：TCAD）接收。</p>
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>肖朝...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2024-5-1</span>
                    </div>
                </div>
            </div>
            <div class="card bg-white rounded-lg shadow-sm overflow-hidden cursor-pointer"
                onclick="openModal('paper8')">
                <div class="aspect-w-16 aspect-h-9">
                    <img src="images/perderTwo.png" alt="论文封面" class="w-full h-full object-cover">
                </div>
                <div class="p-6">
                    <h3 class="text-lg font-semibold text-gray-900 mb-2">ASNPC：面向SNN和类脑处理器协同设计的自动化生成框架</h3>
                    <p class="text-gray-600 text-sm mb-4">本文被CCFB类会议，2025'DATE（Design, Automation and Test in Europe）</p>
                    <div class="flex items-center text-sm text-gray-500">
                        <i class="fas fa-user-circle mr-2"></i>
                        <span>王向宇...</span>
                        <span class="mx-2">|</span>
                        <i class="fas fa-calendar-alt mr-2"></i>
                        <span>2025-1-17</span>
                    </div>
                </div>
            </div>
        </div>
    </main>
    <div id="markdown-container" class="prose max-w-none"></div>
    <!-- Modal -->
    <div id="modal" class="modal fixed inset-0 bg-black bg-opacity-50 hidden z-50 flex items-center justify-center">
        <div class="modal-content bg-white rounded-lg w-full max-w-6xl max-h-[90vh] overflow-hidden mx-4 relative">
            <!-- 添加relative定位 -->
            <div class="p-6 border-b border-gray-200 sticky top-0 bg-white z-10">
                <h2 id="modalTitle" class="text-xl font-semibold text-gray-900 text-center mr-8"></h2> <!-- 添加右侧间距 -->
                <!-- 修改关闭按钮定位 -->
                <button onclick="closeModal()"
                    class="absolute top-4 right-4 text-gray-400 hover:text-gray-500 transition-colors">
                    <i class="fas fa-times text-2xl"></i> <!-- 适当调大图标 -->
                </button>
            </div>
            <div class="h-[calc(90vh-80px)] overflow-y-auto custom-scrollbar p-6">
                <div id="modalImages" class="mb-8"></div>
                <div id="modalContent" class="animate-slide-in"></div>
            </div>
        </div>
    </div>
    <div id="imageOverlay"
        class="fixed inset-0 bg-black bg-opacity-90 hidden z-[999] flex items-center justify-center p-4">
        <div class="relative max-w-full max-h-full">
            <img id="expandedImg" class="max-h-[90vh] mx-auto rounded-lg shadow-xl" alt="放大图片">
            <button onclick="closeImage()"
                class="absolute -top-8 right-0 text-white hover:text-gray-300 transition-colors">
                <i class="fas fa-times text-3xl"></i>
            </button>
        </div>
    </div>
    {% include "footer.njk" %}
    <!-- <footer class="bg-gray-900 text-white py-12">
        <div class="max-w-7xl mx-auto px-4">
            <div class="grid grid-cols-4 gap-8">
                <div>
                    <a href="/" class="font-['Pacifico'] text-2xl text-white mb-6 block">logo</a>
                    <p class="text-gray-400">启元脑芯片实验室致力于脑机接口技术研发与创新，打造智能科技未来。</p>
                </div>
                <div>
                    <h4 class="text-lg font-semibold mb-4">快速链接</h4>
                    <ul class="space-y-2 text-gray-400">
                        <li><a href="index" class="hover:text-white">首页</a></li>
                        <li><a href="news" class="hover:text-white">新闻</a></li>
                        <li><a href="/" class="hover:text-white">论文集</a></li>
                        <li><a href="teamMember" class="hover:text-white">成员</a></li>
                        <li><a href="collaboration" class="hover:text-white">合作</a></li>
                    </ul>
                </div>
                <div>
                    <h4 class="text-lg font-semibold mb-4">合作方式</h4>
                    <ul class="space-y-2 text-gray-400">
                        <li>产学研合作</li>
                        <li>技术授权</li>
                        <li>人才培养</li>
                        <li>项目合作</li>
                    </ul>
                </div>
                <div>
                </div>
            </div>
            <div class="border-t border-gray-800 mt-12 pt-8 text-center text-gray-400">
                <p>© 2024 启元脑芯片实验室. 保留所有权利.</p>
            </div>
        </div>
    </footer> -->
    <script>
        const papers = {
            paper1: {
                title: "VToT：通过LLMs使用思维树提示自动生成Verilog",
                images: ["images/perder0.png", "images/methodology.png", "images/results.png"],
                content: `
                        <div class="space-y-6">
                        <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                        <div><i class="fas fa-user-circle mr-2"></i>周英杰、陈任之、李鑫宇、王静凯、方志刚、王博伟、白文强、曹其林、王蕾</div>
                        <div><i class="fas fa-calendar-alt mr-2"></i>2024-9-23</div>
                        </div>
                        <div class="prose max-w-none">
                        <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                        <p class="mb-6">本文提出了一种结构化的提示方法，显著提高LLM自动生成Verilog代码的正确性。</p>
                        <p class="mb-6">本文生成分析并指出常规思维链(CoT)提示方法在Verilog生成任务中的不一致性；提出了VToT方法，将思维树(ToT, Tree of Thought)与Verilog生成任务相结合；通过在提示中嵌入分层约束、为LLM提供思考路径，生成更符合用户需求的Verilog代码，提高了代码生成任务的正确率。</p>
                        <h3 class="text-lg font-semibold mb-4">研究背景</h3>
                        <p class="mb-6">随着大型语言模型（LLM）的能力不断增强，业界越发关注如何利用LLM辅助硬件设计。虽然LLM在生成程序设计语言时例如Python时表现出较高的正确性，但生成的Verilog却存在功能正确性与语法正确性不足的问题。尽管前序研究尝试将CoT等提示方法用于Verilog生成任务，但CoT的顺序化思维与Verilog硬件描述语言的并行性具有较大的不一致性。</p>
                        <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                        <p class="mb-6">基于链式思维与硬件描述语言的不一致性，本文提出VToT方法：</p>
                        <ul class="list-disc pl-6 mb-6">
                        <li>VToT方法通过推理、生成两个阶段，首先明确设计约束的具体内容；之后再生成符合约束的代码。</li>
                        <li>VToT是一种结构化的提示方法，将复杂大规模设计拆分为多个模块，精细化LLM的思考粒度。</li>
                        <li>在VerilogEval和RTLLM基准测试上的实验结果表明，VToT提示增强了生成代码的语法和功能正确性。</li>
                        </ul>
                        <h3 class="text-lg font-semibold mb-4">实验结果</h3>
                        <p class="mb-6">在VerilogEval和RTLLM基准测试上的实验结果表明，VToT提示增强了生成代码的语法和功能正确性。</p>
                        <ul class="list-disc pl-6 mb-6">
                        <li>在RTLLM 测试基准上，VToT在pass@5达到了75.9%的正确率，比基座模型提高了10.4%。</li>
                        <li>在VerilogEval 测试基准上，VToT发表时达到了当时最先进的性能，在pass@1的正确率为52.4%（提高了8.9%。</li>
                        </ul>
                        <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                        <p class="mb-6">随着LLM的发展，模型的推理能力越来越受到关注；VToT是LLM推理强化进程中，利用领域知识强化Verilog生成推理能力的探索性工作。</p>
                        <p class="mb-6">未来在数据增强下，不断提高模型能力，有助于LLM越来越擅长像专业硬件工程师一样思考，进而促进LLM辅助硬件设计的能力不断进步。</p>
                        </div>
                        </div>
                        `
            },
            paper2: {
                title: "LintLLM：基于大语言模型的开源Verilog Linting框架",
                images: ["images/perderOneF.png", "images/methodsF.png", "images/resultF.png"],
                content: `
                       <div class="space-y-6">
                       <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                       <div><i class="fas fa-user-circle mr-2"></i>方志刚、陈任之、杨智杰、郭阳、戴华东、王蕾</div>
                       <div><i class="fas fa-calendar-alt mr-2"></i>2025-2-15</div>
                       </div>
                       <div class="prose max-w-none">
                       <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                       <p class="mb-6">代码Linting工具对于检测Verilog代码中的潜在缺陷至关重要。传统的Linting工具的局限性在于频繁的误报和冗余的缺陷报告。本文提出了LintLLM，它利用LLM通过Prompt of Logic-Tree和Defect Tracker来检测Verilog代码中的缺陷。此外，我们使用基于突变的缺陷注入技术构建了一个开源Benchmark，以评估LLM检测Verilog缺陷的能力。实验结果表明，与性能最佳的EDA工具相比，o1-mini将正确率提高了18.89\%，并将误报率降低了15.56\%。同时，LintLLM的运行成本不到商用EDA工具的十分之一。这项研究证明了LLM作为一种高效且经济的Linting工具的潜力。开源链接：<a href="https://github.com/fangzhigang32/Static-Verilog-Analysis" target="_blank" class="text-blue-500 hover:underline">https://github.com/fangzhigang32/Static-Verilog-Analysis</a></p>
                       <h3 class="text-lg font-semibold mb-4">研究背景</h3>
                       <p class="mb-6">在寄存器传输级（RTL）设计中，代码质量和编码风格的一致性对构建鲁棒且无缺陷的硬件至关重要。代码Linting工具可通过分析源代码中的潜在缺陷（如风格不一致或不可综合结构）显著降低验证成本。传统的Linting工具依赖预定义的规则匹配，导致大量误报；并且昂贵的授权费用阻碍了中小企业和研究机构的使用。近期，GPT-4等大语言模型（LLM）在Verilog代码相关任务中展现出潜力，引起了科研人员的思考：能否使用LLM检测Verilog设计中的潜在缺陷。</p>
                       <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                       <p class="mb-6">针对传统Linting工具存在的报告冗余和频繁误报的局限性，本文提出的解决方法如下：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>介绍了Prompt of Logic-Tree的提示工程模板，它可以将复杂的求解步骤转换为更易于LLM理解的树状提示。</li>
                       <li>提出了Defect Tracker,它可以定位代码中导致多个次要缺陷的主要缺陷，从而减少缺陷报告的冗余。</li>
                       <li>创建了一个开源基准来评估LLM检测Verilog缺陷的能力，它涵盖了11种缺陷类型，包括90个Verilog设计。</li>
                       </ul>
                       <h3 class="text-lg font-semibold mb-4">实验结果</h3>
                       <p class="mb-6">实验结果表明，LLM的正确率显著优于传统的EDA工具，尤其是在使用Prompt Logic-Tree和Defect Tracker增强后。在评估的LLM中，o1-mini的正确率最高，为83.33%，误报率最低，为12.22%。与表现最佳的商业EDA工具相比，o1-mini的正确率提高了18.89%，误报率降低了15.56%。与Verilator相比，其正确率提高了21.11%，误报率降低了20.00%。在检测成本上，LintLM仅为商业EDA工具的十分之一。</p>
                       <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                       <p class="mb-6">本文介绍了LintLLM，这是一个利用LLM检测Verilog代码缺陷的开源Linting框架。这项研究表明LLM是一种高效且经济的硬件缺陷检测解决方案。</p>
                       <p class="mb-6">未来，我们将探索使用LLM在完成检测后自动修复缺陷，最终获得高质量的RTL设计。</p>
                       </div>
                       </div>
                       `
            },
            paper3: {
                title: "基于 LLM 的处理器验证：神经形态处理器案例研究",
                images: ["images/perderOneX.png", "images/methodsX.png", "images/resultX.png"],
                content: `
                       <div class="space-y-6">
                       <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                       <div><i class="fas fa-user-circle mr-2"></i>肖朝、邓一飞、杨智杰、陈任之、王洪 、赵静月</div>
                       <div><i class="fas fa-calendar-alt mr-2"></i>2024-03-27</div>
                       </div>
                       <div class="prose max-w-none">
                       <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                       <p class="mb-6">本文探索了利用大型语言模型（LLM）加速处理器功能验证的潜力，提出了一种基于LLM的验证工作流，显著提升了验证效率。</p>
                       <p class="mb-6">通过针对RISC-V核心和神经形态处理器的实验，本文展示了LLM在生成测试用例方面的能力，代码覆盖率分别达到89%和91%，为传统处理器和新兴领域专用架构（DSA）的验证提供了新的研究方向。</p>
                       <h3 class="text-lg font-semibold mb-4"> 研究背景</h3>
                       <p class="mb-6">随着硬件设计复杂度的提升，功能验证在硬件设计周期中占据了40%~50%的时间。传统的仿真验证方法虽然灵活，但需要大量人工参与，尤其是对于新兴的领域专用架构（如神经形态处理器），缺乏现成的测试工具和用例。大型语言模型（LLM）因其强大的任务完成能力，为自动化测试生成提供了新的可能性。</p>
                       <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                       <p class="mb-6">本文提出了一种基于LLM的验证工作流，包含以下步骤：  </p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>**测试生成**：通过LLM生成C程序和汇编代码，覆盖RISC-V和神经形态指令集；</li>
                       <li>**编译与仿真**：将生成的测试编译为可执行文件，并在RTL级仿真器中运行；</li>
                       <li>**结果收集与处理**：分析覆盖率数据，指导LLM生成下一轮测试用例，针对未覆盖部分进行优化。</li>
                       </ul>
                       <p class="mb-6">实验中使用GPT-3.5生成36个C程序和128个汇编片段，验证了方法的有效性。 </p>
                       <h3 class="text-lg font-semibold mb-4"> 实验结果</h3>
                       <p class="mb-6">实验结果表明，LLM生成的测试用例能够有效覆盖目标处理器的功能：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>**RISC-V核心**：代码覆盖率达到89%，未覆盖的指令主要为控制状态寄存器相关指令；</li>
                       <li>**神经形态处理器**：代码覆盖率达到91%，得益于其SIMD架构的并行特性。</li>
                       </ul>
                        <p class="mb-6">此外，模块过滤机制优化了资源分配，提升了验证效率。</p>
                       <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                       <p class="mb-6">本文首次将LLM应用于处理器功能验证，展示了其在传统架构和新兴DSA中的潜力。未来研究方向包括：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>自动化覆盖率结果到自然语言提示的转换，减少人工干预；</li>
                       <li> 结合深度学习方法，使LLM能够自主理解新架构，进一步提升验证效率。</li>
                       </ul>
                       </div>
                       </div>
                       `
            },
            paper4: {
                title: "LLM-TG：利用大型语言模型实现处理器测试用例的自动生成",
                images: ["images/perderOneD.png", "images/methodsD.png", "images/resultD.png"],
                content: `
                       <div class="space-y-6">
                       <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                       <div><i class="fas fa-user-circle mr-2"></i>邓一飞、陈任之、肖朝、杨智杰、罗远锋、赵静月</div>
                       <div><i class="fas fa-calendar-alt mr-2"></i>2024-10-24</div>
                       </div>
                       <div class="prose max-w-none">
                       <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                       <p class="mb-6">本文提出了一种基于大型语言模型（LLM）的自动化测试用例生成框架LLM-TG，显著提高了处理器功能验证的效率和覆盖率。</p>
                       <p class="mb-6">本文通过分析传统验证方法的局限性，设计了一种结合规则约束、反馈机制和提示库的LLM驱动流程；实验结果表明，在RISC-V处理器验证中，LLM-TG的模块覆盖率和表达式覆盖率分别比现有最优方法（RISCV-DV和LLM4DV）提升至少8.34%和5.8%，为处理器验证提供了高效、自动化的新范式。 </p>
                       <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                       <p class="mb-6">LLM-TG框架包含四个核心组件：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>**基于提示的测试生成**：通过规则提示（约束编译环境）和模块提示（定向生成功能测试）驱动LLM生成多样化测试用例；</li>
                       <li>**LLM辅助优化**：利用编译/仿真错误反馈自动修正测试用例，提升正确率；</li>
                       <li>**覆盖率反馈机制**：根据未覆盖指令和模块动态调整提示，实现迭代优化；</li>
                       <li>**开源提示库**：整合已验证的高效提示模板，加速后续测试生成。</li>
                       </ul>
                       <p class="mb-6">实验基于RV64GC架构处理器，生成64个汇编和79个C程序验证有效性。</p>
                       <h3 class="text-lg font-semibold mb-4">实验结果</h3>
                       <p class="mb-6">在XuanTie-C910处理器上的实验显示：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>**覆盖率提升**：核心模块（ct_core）的块覆盖率达84.58%，较基线方法最高提升8.6%；</li>
                       <li>**错误率优化**：规则提示和LLM辅助优化使仿真通过率从56.8%提升至95.9%；</li>
                       <li>**效率改进**：提示库复用减少2.5倍提示量，保持相同覆盖率。</li>
                       </ul>
                       <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                       <p class="mb-6">LLM-TG通过结构化提示和闭环反馈，证明了LLM在系统级验证中的潜力。未来方向包括： </p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>**模型微调**：减少人工干预，提升LLM对新型架构的自主适配能力；</li>
                       <li>**变异增强**：结合传统变异测试方法，进一步优化覆盖率。</li>
                       </ul>
                       </div>
                       </div>
                       `,
            },
            paper5: {
                title: "PerturbGen：一个基于种群扰动的硬件测试生成框架",
                images: ["images/perderW.png", "images/methodsW.png", "images/resultW.png"],
                content: `
                       <div class="space-y-6">
                       <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                       <div><i class="fas fa-user-circle mr-2"></i>王静凯、王蕾、陈任之</div>
                       <div><i class="fas fa-calendar-alt mr-2"></i>2024-11-20</div>
                       </div>
                       <div class="prose max-w-none">
                       <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                       <p class="mb-6">本文提出了一个种群扰动的硬件测试生成框架PerturbGen，显著提升处理器验证中的覆盖率。</p>
                       <p class="mb-6">本文分析并之处了传统随机测试生成方法存在的关联性缺失、饱和效应和盲目性的三大局限性；进而提出了PerturbGen，将扰动进化的思想应用于测试生成；提出了种群级胡扰动与成员级自扰动相结合的两级扰动机制，构建覆盖率引导的反馈环路，提高了生成测试的覆盖率水平。</p>
                       <h3 class="text-lg font-semibold mb-4">研究背景</h3>
                       <p class="mb-6">随着处理器设计的日益复杂，验证环节的难度与开销愈发增大，业界逐步重视如何生成覆盖率更高的测试。当前随机指令生成器得到的指令序列缺乏上下文相关性，难以覆盖深层次区域；传统测试工具存在饱和效应，覆盖率提升遇到瓶颈，同时缺乏反馈机制，无法有效利用现有覆盖率信息指导测试生成。</p>
                       <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                       <p class="mb-6">基于编程语言的语法特性和扰动进化的思想，本文提出PerturbGen方法：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>PerturbGen通过互扰动、自扰动两个阶段生成新的硬件测试，首先通过抽象语法树的节点交换实现程序结构重组，然后基于组合图实现细粒度程序成分变异。</li>
                       <li>PerturbGen设计了覆盖率引导的反馈环路，根据多种覆盖率指标和混合选择策略，平衡迭代过程中的探索与利用。</li>
                       <li>PerturbGen基于开源RISC-V处理器设计了自动化仿真流程，并在其上进行了方法验证。</li>
                       </ul>
                       <h3 class="text-lg font-semibold mb-4">实验结果</h3>
                       <p class="mb-6">在Xuantie-C910上的实验结果表明，PerturbGen的三种覆盖率指标均优于基线方法：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>在块覆盖率、表达式覆盖率和翻转覆盖率上，PerturbGen的提升幅度分别为3.56%、5.70%和14.01%。</li>
                       <li>结合混合选择策略的反馈环路，使生成测试的覆盖率呈现出随着迭代从广泛探索到平稳收敛的特征。</li>
                       <li>消融实验证明两种扰动机制对覆盖率提升至关重要；混合选择策略同时确保了种群覆盖率的单调性上升以及更高的饱和上限。</li>
                       </ul>
                       <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                       <p class="mb-6">随着处理器的发展，验证的效果和效率越发重要；PerturbGen是在随机测试生成器基础上，利用扰动进化机制探索程序成分组合以提高覆盖效果的工作。</p>
                       <p class="mb-6">未来研究将多样化扰动的成分与方式，并借助大型语言模型等技术构建更具潜力和多样性的初始种群，进而促进自动化处理器验证的效果不断进步。</P>
                       </div>
                       </div>
                       `,
            },
            paper6: {
                title: "针对可配置神经形态处理器的硬件与算法协同设计",
                images: ["images/perderOneL.jpg", "images/methodsL.png", "images/resultL.png"],
                content: `
                        <div class="space-y-6">
                        <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                        <div><i class="fas fa-user-circle mr-2"></i>李媛、陈任之、杨智杰、肖勋、赵静月、朱振华、戴华东、唐玉华、徐炜遐、罗莉、王蕾</div>
                        <div><i class="fas fa-calendar-alt mr-2"></i>2024-11-8</div>
                        </div>
                        <div class="prose max-w-none">
                        <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                        <p class="mb-6">研究表明，脉冲神经网络硬件-算法协同设计能够在优化算法性能的同时降低硬件开销。然而，高维、混合变量类型的协同设计空间与耗时的硬件验证流程，是高效解决硬件-算法协同设计问题的主要挑战。为解决这些问题：</p>
                        <ul class="list-disc pl-6 mb-6">
                       <li>我们提出一种通用的三阶段硬件/算法协同设计框架；</li>
                       <li>针对可重构神经形态处理器，将硬件参数与网络架构参数集成于统一的设计空间；</li>
                       <li>建立通用分析模型以快速评估参数规模与功耗指标，支撑设计空间探索中的候选方案高效验证；</li>
                       <li>通过引入分解策略将单目标优化算法TPE扩展为多目标优化算法MOTPE/D。本研究的创新点体现在：首次采用分解策略改进TPE算法，使其具备处理多目标优化问题的能力，并通过理论建模实现了硬件性能的快速预估，从而显著提升了协同设计效率；</li>
                       </ul>
                        <h3 class="text-lg font-semibold mb-4">研究背景</h3>
                        <p class="mb-6">作为传统深度学习方法的生物合理性替代方案，脉冲神经网络（Spiking Neural Network, SNN）因其稀疏且事件驱动的信息处理机制，展现出高效的计算效率，特别适用于边缘计算设备或嵌入式系统等资源受限场景。然而，由于基于商用CPU/GPU的边缘平台未针对SNN部署进行优化，SNN稀疏二进制激活、低功耗和低延迟优势往往难以充分发挥。</p>
                        <p class="mb-6">当前提升硬件部署SNN性能的研究主要沿两个方向展开：在硬件层面，研究者提出了多种神经形态处理器或高度定制化的SNN加速器以支持大规模SNN运行，但这些通用或专用硬件架构在面对不同网络结构时难以持续保持优异性能；在算法层面，大量硬件感知的SNN神经架构搜索（NAS）研究试图针对特定神经形态处理器优化网络架构，但固定硬件设计会导致最优SNN架构分布偏移，从而产生次优解。因此，必须通过神经形态处理器与网络架构的协同设计来提升SNN模型在硬件平台上的性能表现。</p>
                        <p class="mb-6">由于SNN网络与处理器架构的协同设计空间巨大，手工协同设计难以实现。目前自动化的硬件-算法协同设计方法主要分为三类：可微分NAS、强化学习和进化算法。最新研究指出，可微分NAS和进化方法易陷入局部最优，而基于强化学习的方法需要大量训练数据和计算资源来学习有效策略。此外，针对每个候选硬件-算法组合方案，耗时的SNN模型训练与复杂的硬件验证构成了双重挑战。</p>
                        <p class="mb-6">基于上述分析，我们针对SNN算法与可重构神经形态处理器提出三阶段软硬件协同设计框架。本工作的主要贡献可概括如下：</p>
                         <ul class="list-disc pl-6 mb-6">
                       <li>提出可重构神经形态处理器的高层抽象结构，并将SNN模型与处理器架构搜索参数化于统一的设计空间。</li>
                       <li>建立了神经形态处理器上SNN运行的通用参数量计算与功耗估计解析模型，加速搜索过程中候选方案的筛选。</li>
                       <li>针对高维、混合变量类型的设计空间以及昂贵评估等挑战，提出基于Tchebycheff分解策略的多目标优化算法MOTPE/D。</li>
                       </ul>
                        <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                          <!-- 添加两张并排图片 -->
                          <div class="flex justify-center items-center gap-4 my-6">
                              <div class="w-1/2">
                                  <img src="images/algorithmL.png" 
                                       alt="算法流程图" 
                                       class="w-full h-48 object-contain rounded-lg shadow-lg hover:scale-105 transition-transform duration-300 cursor-zoom-in"
                                       onclick="expandImage(event, this.src)">
                              </div>
                              <div class="w-1/2">
                                  <img src="images/DefinitionL.png" 
                                       alt="定义示意图" 
                                       class="w-full h-48 object-contain rounded-lg shadow-lg hover:scale-105 transition-transform duration-300 cursor-zoom-in"
                                       onclick="expandImage(event, this.src)">
                              </div>
                          </div>
                        <p class="mb-6">Table Ⅰ为协同设计空间各参数的解释及搜索范围。**n** 表示液态神经元数量，**C<sub>ei</sub>** 为兴奋性与抑制性神经元间的连接系数，同时**C<sub>ee</sub>**、**C<sub>ie</sub>**、**C<sub>ii</sub>** 分别对应兴奋性-兴奋性、抑制性-兴奋性、抑制性-抑制性神经元连接系数，**θ<sub>e</sub>** 与 **θ<sub>i</sub>** 分别代表兴奋性和抑制性神经元的发放阈值，**h<sub>1</sub>** 和 **h<sub>2</sub>** 表示读出层MLP中第一隐藏层与第二隐藏层的神经元数目。因此，液态神经元数量n对芯片面积和静态功耗具有主要影响。连接系数（C<sub>in</sub>、C<sub>ee</sub>、C<sub>ei</sub>、C<sub>ie</sub>和C<sub>ii</sub>）调控神经元的连接概率，值越高将导致模型内部连接增多，存储于神经形态硬件的连接矩阵规模扩大，且神经元计算单元（NU）间的脉冲传输频率将进一步增高，因此导致芯片面积、片上存储需求以及功耗的增加。神经元发放阈值θ<sub>e</sub>和θ<sub>i</sub>主要影响各NU的脉冲发放行为。</p>
                        <h4 class="text-lg font-semibold mb-4">参数量与功耗建模</h4>
                        <ul class="list-disc pl-6 mb-6">
                        <li>分类准确率模型（Accuracy）:模型分类性能通过准确率指标量化，其定义为测试集中被正确分类的样本数量与总样本数量的比值。具体计算时，设$N_{\text{correct}}$表示经模型预测后标签与真实标签一致的样本数量，$N_{\text{total}}$代表测试集总样本量，则准确率$\text{acc}$可表示为二者之比。该指标直接反映模型在特定任务中的分类效果。</li>
                        <div class="flex justify-center my-4">
                            <img src="images/sccuracy.png" 
                                 alt="" 
                                 class="w-48 h-24 object-contain rounded-lg shadow-lg hover:scale-105 transition-transform duration-300 cursor-zoom-in"
                                 onclick="expandImage(event, this.src)">
                        </div>
                        <li>参数量模型（Parameter Size）:神经网络的存储开销主要来源于突触连接参数的存储需求。每个突触连接需要完整存储三个关键参数：源神经元索引、目标神经元索引以及突触权重值。因此，总参数量可表述为所有突触连接数量的三倍。具体计算中，需分别统计五类突触连接的数量：输入层到兴奋性神经元的连接数$w_{\text{in-e}}$、兴奋性神经元间的连接数$w_{\text{ee}}$、兴奋性到抑制性神经元的连接数$w_{\text{ei}}$、抑制性到兴奋性神经元的连接数$w_{\text{ie}}$，以及抑制性神经元间的连接数$w_{\text{ii}}$。这些连接数的总和乘以3即得到整体参数量。</li>
                         <div class="flex justify-center my-4">
                            <img src="images/params.png" 
                                 alt="" 
                                 class="w-48 h-24 object-contain rounded-lg shadow-lg hover:scale-105 transition-transform duration-300 cursor-zoom-in"
                                 onclick="expandImage(event, this.src)">
                        </div>
                        <li>功耗模型（Power Consumption）:处理器总功耗包含静态功耗与动态功耗两个组成部分。静态功耗由基础漏电功耗$P_{\text{leak}}$和时钟驱动功耗$P_{\text{idle}} \times F_{\text{clk}}$构成，其中$P_{\text{leak}}$反映晶体管固有漏电流导致的能耗，$P_{\text{idle}}$表示单位时钟周期的静态能耗，$F_{\text{clk}}$为工作时钟频率。动态功耗$P_{\text{so}}$则源于突触操作（Synaptic Operation, SO）的能耗积累，由单次突触操作能耗$E_{\text{SO}}$与平均操作速率$r_{\text{SO}}$的乘积决定。动态功耗的具体计算需要统计脉冲事件触发的突触操作总量。对于包含$N_1$个神经元的输入层，每个神经元$i$在运行期间会产生$IN_i$次脉冲事件，且每个脉冲会激活其连接的$DE_i$个目标神经元。同理，液态层中$N_2$个神经元的脉冲活动也需统计，其中神经元$j$产生$LS_j$次脉冲，每次脉冲影响$LD_j$个下游神经元。将输入层和液态层的突触操作总数相加，除以总运行时间$T$得到平均突触操作速率，最终乘以单次操作能耗$E_{\text{SO}}$即可获得动态功耗估值。</li>
                         <div class="flex justify-center my-4">
                            <img src="images/power.png" 
                                 alt="" 
                                 class="w-48 h-24 object-contain rounded-lg shadow-lg hover:scale-105 transition-transform duration-300 cursor-zoom-in"
                                 onclick="expandImage(event, this.src)">
                        </div>
                        </ul>
                        <h4 class="text-lg font-semibold mb-4">MOTPE/D算法</h4>
                        <p class="mb-6">本研究提出改进的多目标优化算法MOTPE/D（Multi-Objective Tree-structured Parzen Estimator based on Decomposition），其算法流程如下所示。</p>
                        <p class="mb-6">对于第$j$次迭代，算法执行以下步骤：</p>
                        <ul class="list-disc pl-6 mb-6">
                        <li>首先对历史观测数据$(x,y)$进行分解转换：$y=F(x)$为原始目标函数值，$\lambda^j$为从均匀分布权重向量集$S$中随机选取的权重向量，$r_i$为参考点坐标。</li>
                           <div class="flex justify-center my-4">
                            <img src="images/max.png" 
                                 alt="" 
                                 class="w-48 h-24 object-contain rounded-lg shadow-lg hover:scale-105 transition-transform duration-300 cursor-zoom-in"
                                 onclick="expandImage(event, this.src)">
                        </div>
                        <li>基于分位数$\gamma$将转换后的观测序列$D_j$划分为：优质解集** $D_j^l = \{(x,h) | x \in \text{top-}\lceil \gamma \times |D_j| \rceil \text{的观测值}\}$和**劣质解集** $D_j^g = D_j \setminus D_j^l$。</li>
                        <li>概率估计与采样：基于优质解集$D_j^l$和劣质解集$D_j^g$的分布估计分别构建概率密度函数：$l_j(x)$和$g_j(x)$，采用期望改进EI采集函数采样下一个样本点：</li>
                           <div class="flex justify-center my-4">
                            <img src="images/argMax.png" 
                                 alt="" 
                                 class="w-48 h-24 object-contain rounded-lg shadow-lg hover:scale-105 transition-transform duration-300 cursor-zoom-in"
                                 onclick="expandImage(event, this.src)">
                        </div>
                        <li>解的评估与Pareto解集更新：评估候选解$x^*$获得$y^*=F(x^*)$，更新Pareto前沿解集，并将$(x^*,y^*)$加入历史观测数据集$D$，在达到预设迭代次数后输出Pareto最优解集。</li>
                        </ul>
                        <h3 class="text-lg font-semibold mb-4">实验结果</h3>
                        <p class="mb-6">在每个任务中，我们进行了500轮搜索，并选取四个典型解进行对比分析：**最高精度解（$S_{acc}$）**，**最小参数量解（$S_{params}$）**， **最低功耗解（$S_{power}$）**和**拐点解（Knee Point）**。在N-MNIST分类任务上现有最优方案能够达到98.38%的准确率，但需要10,625个神经元单元，其硬件开销为本方案的31倍。本研究所得的拐点解在准确率降低2.3%的前提下，将神经元数量降至341个。在DVS-128分类任务上，拐点解在准确率、参数量与功耗三维目标间达成最佳权衡，同时保持与SOTA相当的分类精度。</p>
                        <p class="mb-6">消融实验结果分析：本研究在三个案例场景下，对比了MOTPE/D、MOTPE和ParEGO三种算法在仅进行500次评估时获得的帕累托解集。为直观展示算法性能，将所有算法发现的帕累托解进行统一非支配排序筛选，最终在图3中仅保留未被其他算法解支配的帕累托解。实验结果表明，在三个任务中，MOTPE/D搜索获得的帕累托解具有显著更高的存活率，且解集沿帕累托前沿呈现均匀分布特性，能够充分满足决策者对不同目标的差异化偏好需求。</p>
                        <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                        <p>本研究面向脉冲神经网络与神经形态处理器提出通用的三阶段硬件-算法协同设计框架，其核心创新点包括：针对高维混合变量空间下的昂贵评估优化问题，提出多目标优化算法MOTPE/D（基于分解策略的多目标树结构Parzen估计器）；该算法通首次建立液态状态机（LSM）在神经形态处理器上的通用功耗解析模型；在仅进行500次搜索之后，相较于对比算法MOTPE和ParEGO，MOTPE/D能够找到质量更优的帕累托最优解集。</p>
                        </div>
                        </div>
                        `
            },
            paper7: {
                title: "大规模脉冲卷积神经网络到资源受限类脑处理器的分层映射",
                images: ["images/perderTwoX.png","images/perderThreeX.png", "images/methodsTwoX.png", "images/resultsTwoX.png"],
                content: `
                       <div class="space-y-6">
                       <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                       <div><i class="fas fa-user-circle mr-2"></i>肖朝、贺旭、杨智杰、肖勋、王耀、龚锐、铁俊波、王蕾、徐炜遐 </div>
                       <div><i class="fas fa-calendar-alt mr-2"></i>2024-5-1</div>
                       </div>
                       <div class="prose max-w-none">
                       <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                       <p class="mb-6">类脑处理器被设计为非冯·诺依曼系统，用于高效执行脉冲神经网络（SNN）。脉冲卷积神经网络（SCNN）结合了卷积神经网络和脉冲卷积神经网络的优势，已广泛应用于视觉任务。然而，随着SCNN规模的增大，在资源受限的类脑处理器上执行大规模SCNN面临许多挑战，包括由于资源竞争导致的突触剪枝过多、执行性能下降等问题。为了解决这些问题，我们提出了一种有效的方法，将大规模SCNN映射到资源受限的类脑处理器上。</p>
                       <p class="mb-6">该方法包括三个步骤：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>拆分</li>
                       <li>划分</li>
                       <li>映射</li>
                       </ul>
                       <p class="mb-6">我们探索了三种无环拆分策略，将大规模SCNN分割成子网络，避免循环依赖。轴突共享是将子网络划分为多个集群的指导原则。为了获得最佳的集群到计算核心的映射方案，我们使用非支配排序遗传算法协同优化两个指标。我们通过八个实际的SCNN应用评估了我们的方法。结果表明，与现有的最新方法相比，我们的方法显著减少了突触剪枝和精度损失，并提高了执行性能。</p>
                       <h3 class="text-lg font-semibold mb-4">研究背景</h3>
                       <p class="mb-6">脉冲神经网络（SNN）作为受生物神经系统启发的新型计算架构，凭借其事件驱动的脉冲信息处理机制，被公认为下一代人工智能计算范式的有力竞争者。SNN以离散时空脉冲作为信息载体进行通信和计算。脉冲卷积神经网络（SCNN）有机融合了传统卷积神经网络的结构优势与SNN的脉冲信息处理机制，在视觉认知任务中展现出巨大应用潜力。然而，SCNN的多层级联特性导致其网络规模显著大于传统SNN，这对硬件部署提出了特殊挑战。</p>
                       <p class="mb-6">为突破SNN的硬件加速瓶颈，学界已研发出多款专用类脑处理器，包括英特尔的Loihi系列、IBM的TrueNorth、SpiNNaker以及国防科技大学Unicorn等典型代表。这类处理器普遍采用多核架构：每个计算核集成有限数量的脉冲神经元与突触单元，通过片上网络（NoC）实现核间脉冲通信。这种设计虽然保证了可扩展性，但也为SCNN的硬件映射带来三大核心挑战：首先，单核硬件资源（尤其是输入轴突资源）的物理约束将导致突触连接的大规模剪枝，直接影响模型精度。其次，次优的SCNN映射方案会引发较高的NoC通信延迟：由于单个计算核的神经元容量限制，相互连接的神经元往往分布于不同计算核，这种跨核分布的神经元连接会产生大量脉冲数据包，引发较高的通信延迟。最后，当面对超大规模SCNN模型时，必须进行模型分割并分时加载。但脉冲神经元特有的时序依赖特性使得模型分割变得复杂。</p>
                       <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                       <p class="mb-6">为了将大规模的SCNN模型部署到资源受限的多核类脑处理器，提出了一种层次化映射映射的方法，该方法包括：</p>
                       <ul class="list-disc pl-6 mb-6">
                       <li>无环的子网络分割，基于SCNN卷积层神经元空间拓扑的局部性特征，创新性地提出坐标对齐的神经元组划分准则：将特征图中相同空间坐标(x,y)的神经元聚合为最小通信单元。该策略充分利用相邻层间神经元的空间位置一致性，在保证子网间无环形依赖的前提下，将原始网络解构为多个硬件可承载的独立子网络；</li>
                       <li>轴突共享的集群划分，该策略基于同源像素点的神经元拥有相同的输入神经元（在硬件中表现为相同的输入轴突）的事实，以神经元组为基本单位将子网络划分为多个神经元集群；</li>
                       <li>多目标协同优化的集群到核心映射，以平均通信距离和最大通信负载为优化目标，采用改进型NSGA-II算法进行Pareto前沿搜索。</li>
                       </ul>
                       <h3 class="text-lg font-semibold mb-4">实验结果</h3>
                       <p class="mb-6">本研究选用8个典型SCNN基准模型（包括S-AlexNet、S-VGG等）），与SentryOS、HSC-FD和SNEAP三种前沿方法相比，本方法展现出显著优势：1）在真实的硬件资源约束下，本方法突触剪枝率较对比方法平均降低31.5%，41.1%和8.0%。在对CIFAR10-DVS数据集分类的任务中，相比于完整的模型，我们的方法仅降低精度0.08%，而其他三个方法降低精度3.61%, 30.11%和18.15%；2）与SentryOS、HSC-FD和SNEAP相比，我们的方法平均减少了74.4%、66.66%和24.9%的通信流量，80.3%、59.4%和31.5%的通信功耗。</p>
                       <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                       <p class="mb-6">这项研究旨在优化在硬件资源受限的类脑处理器上执行大规模SCNN模型时的突触剪枝和执行性能，提出了一种层次化的SCNN映射策略，包含无环子网络分割、轴突共享的集群划分以及多目标协同优化的集群到核心映射。实验结果表明，该方法在突触剪枝、模型精度、能量消耗和吞吐量方面表现出更优的性能。</p>
                       <p class="mb-6">随着SNN模型的发展，研究人员提出了一些SCNN的变体，例如层内神经元之间具有循环连接。在这些新型SCNN模型中直接应用本文提出的方法可能会存在一定的局限性。因此，我们将在未来针对这些新型结构的SNN模型，开展在类脑处理器上的映射部署设计和进一步研究。</P>
                       </div>
                       </div>
                       `,
            },
            paper8: {
                title: "ASNPC：面向SNN和类脑处理器协同设计的自动化生成框架",
                images: ["images/perderTwoW.png", "images/methodsTwoW.png", "images/resultsTwoW.png"],
                content: `
                       <div class="space-y-6">
                       <div class="flex items-center space-x-4 text-sm text-gray-500 mb-6">
                       <div><i class="fas fa-user-circle mr-2"></i>王向宇、李媛、杨智杰、肖朝、肖勋、陈任之、徐炜遐、王蕾 </div>
                       <div><i class="fas fa-calendar-alt mr-2"></i>2025-1-17</div>
                       </div>
                       <div class="prose max-w-none">
                       <h3 class="text-xl font-bold text-primary mb-4">摘要</h3>
                       <p class="mb-6">脉冲神经网络（SNNs）被认为是传统深度神经网络的有前景的节能替代方案。与此同时，类脑处理器的开发也在不断增加，以支持大规模SNNs的高效执行。然而，目前的工作往往将设计分开，主要优先考虑单一标准。硬件-算法协同设计允许在设计过程中同时考虑硬件和算法特性，有效减少资源使用，同时优化算法性能。鉴于此，我们开发了一个名为ASNPC的硬件-算法协同设计框架，针对SNNs和类脑处理器。考虑到广泛的混合变量协同设计空间和时间成本高昂的功能评估，我们采用了基于代理的多目标优化算法MOTPE，以识别平衡算法性能和硬件成本的帕累托解。为了快速获得硬件结果，我们设计了一种端到端的方法论，可以使用硬件库中的模板自动生成与每个候选项对应的神经形态处理器的寄存器传输级（RTL）代码。评估的硬件指标，如硬件资源和功耗，随后反馈给MOTPE以进行下一个候选项的选择。与现有工作相比，所提出的方法能够在有限的搜索预算内找到更好的帕累托解，使其有效适应各种应用场景。此外，在相同的硬件配置下，我们生成的类脑处理器实现了更低的硬件资源使用和更高的吞吐量。</p>
                       <h3 class="text-lg font-semibold mb-4">研究背景</h3>
                       <p class="mb-6">LSM，即脉冲版本的储层计算，是一种包含前馈和循环连接的脉冲神经网络（Spiking Neural Network, SNN）。LSM 通常由三个部分组成：负责脉冲编码的输入层、生成特征向量的液体层，以及与任务相关的读取层。LSM 巧妙地避免了一般循环 SNN 模型的训练难题，因为仅需训练读取层的权重。其丰富的动态特性和极低的训练开销，使 LSM 成为边缘系统的理想网络模型。液体层是 LSM 的核心部分，由兴奋性和抑制性神经元组成一个随机且循环互联的池。在本工作中，采用泄漏积分发放（LIF）神经元模型来模拟所有神经元的行为。我们采用了一种几何结构生成方法来构建液体层，此方法受到“距离越近，互连的可能性越大”这一概念的启发。</p>
                       <h3 class="text-lg font-semibold mb-4">研究方法</h3>
                       
                       <ul c<p class="mb-6">我们提出了一种硬件-算法协同设计方法。该方法包括三个部分：</p>lass="list-disc pl-6 mb-6">
                       <li>首先，我们从算法和硬件设计中识别相关的设计变量。在算法方面，设计空间包括与网络拓扑和神经元动态特性相关的参数。在硬件方面，设计空间包括与硬件性能相关的架构参数。</li>
                       <li>其次，考虑到协同设计空间的复杂性，我们使用多目标优化搜索策略，该策略通过使用软件生成的准确率结果和硬件性能结果来更新代理模型和帕累托前沿，从而生成更优的候选参数用于后续搜索。</li>
                       <li>最后，在确认相关参数后，我们在软件框架上实现代码，并使用端到端框架集成来自硬件库的代码块，生成相应的硬件设计，并输出评估结果。</li>
                       </ul>
                       <p class="mb-6">为了应对混合变量协同设计空间和耗时评估带来的挑战，我们采用 MOTPE 来寻找平衡算法性能和硬件效率的帕累托前沿。MOTPE 通过自适应 Parzen 估计器构建的树结构分层过程，能够自然地处理连续和离散变量。</p>
                       <p class="mb-6">对于算法使用的网络结构，我们采用模块化方法设计适用于 LSM 的硬件架构，以便实现细粒度的硬件优化。然后，我们使用这些 RTL 模块构建一个硬件库。为了提高最终设计的灵活性，我们使每个 RTL 模块都具有可配置性。代码库包含各种类型的可配置代码块，包括神经元模块、控制器模块、缓冲模块和存储模块等。此外，网络配置信息存储在配置文件中，端到端框架将根据配置信息重新生成库中的相关代码块。最终，生成的代码块和配置文件用于生产最终的神经形态处理器</p>
                       <p class="mb-6">鉴于硬件资源的限制，我们的神经元单元在网络计算过程中设计为可复用。在复用神经元单元时，我们设置了多个存储模块来保存信息，并根据复用次数重新划分权重。根据用户指定的行和列复用次数，可以将原网络中的神经元划分为多个块，进行顺序计算。相应的行和列模块需要额外的存储块来存储该区域内神经元的权重，地址管理基于行和列复用次数。我们在二维流片阵列中安排了多个处理单元，以实现流水线计算。</p>
                       <p class="mb-6">我们使用 TCL 命令实现端到端生成工作流程。首先，根据搜索算法提供的参数，我们从 RTL 代码块中调用模板并执行生成文件所需的 Python 脚本，以生成相应的代码输出。然后，根据新生成的文件创建项目，并对项目进行综合和实现。最后，通过正则表达式从硬件报告中提取评估结果。</p>
                       <p class="mb-6">最终，我们将获得与 LSM 相对应的硬件设计以及相关的硬件评估结果，如资源利用率和功耗。随后，我们可以利用这些信息执行 MOTPE 算法，从而生成改进的候选解决方案。</p>
                       <h3 class="text-lg font-semibold mb-4">实验结果</h3>
                       <p class="mb-6">与 S2N2 框架相比，我们的设计分别减少了查找表（LUT）和触发器（FF）资源使用量 53.07% 和 29.95%，且未使用任何 DSP 资源。此外，我们实现了更高的吞吐量。</p>
                       <p class="mb-6">与 NSGA II相比，可以很容易发现 MOTPE 总能找到更多的帕累托解，并推动帕累托前沿前进。分析认为，作为一种基于遗传算法的启发式算法，NSGA II通常在早期阶段表现出较慢的收敛性，特别是在种群多样性较高时。因此，接近帕累托前沿需要大量的评估。</p>
                       <p class="mb-6">与最大准确率相比，我们识别的帕累托前沿在准确率和硬件开销之间取得了平衡，在三个数据集上的准确率分别略微降低了 2.26%、1.50% 和 2.50%。然而，这带来了 LUT 开销分别减少 34.49%、30.94% 和 24.49%，以及 FF 开销分别减少 33.50%、28.75% 和 22.08% 的显著降低。由于在 FPGA 上的功耗评估被认为不可靠，我们未将功耗作为评估信息。
</p>
                       <p class="mb-6">上述结果表明，尽管在不同的应用场景中使用 MOTPE 算法可获得高准确率，但也带来了显著的硬件开销。通过选择合适的参数，可以在准确率和硬件成本之间实现有效平衡，大幅减少硬件资源使用量，同时保持相对较低的准确率下降。这表明，尽管牺牲了一定的准确率，此类硬件优化在资源受限的应用场景中可以增强系统的整体效率。</p>
                       <h3 class="text-lg font-semibold mb-4">结论与展望</h3>
                       <p class="mb-6">在本文中，我们提出了ASNPC，这是一种基于算法定义硬件概念的硬件-算法协同设计方法论，专门用于LSM。我们开发了一个专门的端到端框架，以便在FPGA上快速部署LSM并获得真实的硬件性能指标。选择并应用了MOTPE算法在三个数据集上，以证明协同设计方法的有效性。实验结果表明，我们的端到端框架在硬件性能上优于其他方法，并且资源使用更少。此外，MOTPE算法识别出更高质量的Pareto最优解，并在不同数据集上实现了更优的准确性。此外，通过平衡准确性和硬件成本，我们的框架显著降低了硬件资源使用，仅造成轻微的准确性损失。</p>
                       </div>
                       </div>
                       `,
            },
        };
        // 修改后的openModal函数
        function openModal(paperId) {
            fetch(`src/markdown/${paperId}.md`)
                .then(response => response.text())
                .then(markdown => {
                    const renderedHTML = marked(markdown);

                    // 创建一个临时容器来解析 Markdown 内容
                    const tempDiv = document.createElement('div');
                    tempDiv.innerHTML = renderedHTML;

                    // 提取封面图片
                    const coverImage = tempDiv.querySelector('img');
                    if (coverImage) {
                        document.getElementById('modalImages').innerHTML = `<img src="${coverImage.src}" alt="封面图片" class="w-full rounded-lg">`;
                        coverImage.remove(); // 移除正文中的封面图片
                    }

                    // 将剩余内容插入模态框
                    document.getElementById('modalContent').innerHTML = tempDiv.innerHTML;
                })
                .catch(error => {
                    console.error('加载 Markdown 文件失败:', error);
                    document.getElementById('modalContent').innerHTML = '<p>内容加载失败，请稍后重试。</p>';
                });

            document.getElementById('modal').classList.remove('hidden');
            document.documentElement.style.overflow = 'hidden';
            document.body.style.overflow = 'hidden';
        }
        function expandImage(event, index, paperId) {
            event.stopPropagation();
            const paper = papers[paperId];
            const imageUrl = paper.images[index];

            const overlay = document.getElementById('imageOverlay');
            const expandedImg = document.getElementById('expandedImg');

            // 初始化缩放状态
            let scale = 1;
            expandedImg.style.transform = `scale(${scale})`;

            // 加载图片
            expandedImg.src = imageUrl;
            overlay.classList.remove('hidden');
            document.body.style.overflow = 'hidden';

            // 滚轮缩放处理函数
            const handleWheel = (e) => {
                e.preventDefault();
                const delta = e.deltaY > 0 ? 0.9 : 1.1;
                scale = Math.min(Math.max(0.5, scale * delta), 3); // 限制缩放范围0.5-3倍
                expandedImg.style.transform = `scale(${scale})`;
                expandedImg.style.transformOrigin = `${e.offsetX / expandedImg.offsetWidth * 100}% ${e.offsetY / expandedImg.offsetHeight * 100}%`;
            };

            // 添加滚轮事件监听
            expandedImg.addEventListener('wheel', handleWheel);

            // 点击关闭处理
            expandedImg.onclick = function (e) {
                if (scale !== 1) {
                    scale = 1;
                    expandedImg.style.transform = 'scale(1)';
                } else {
                    closeImage();
                }
            };

            // 关闭时清理事件监听
            overlay._cleanup = () => {
                expandedImg.removeEventListener('wheel', handleWheel);
                delete overlay._cleanup;
            };
        }

        function closeImage() {
            const overlay = document.getElementById('imageOverlay');
            overlay.classList.add('hidden');
            document.body.style.overflow = 'auto';

            // 重置缩放状态
            const expandedImg = document.getElementById('expandedImg');
            expandedImg.style.transform = 'scale(1)';

            // 执行清理
            if (overlay._cleanup) overlay._cleanup();
        }
        function closeImage() {
            document.getElementById('imageOverlay').classList.add('hidden');
            document.body.style.overflow = 'auto';
            const expandedImg = document.getElementById('expandedImg');
            expandedImg.classList.remove('zoomed');
            document.getElementById('magnifier').style.display = 'none';
        }
        // 添加窗口resize监听
        window.addEventListener('resize', () => {
            if (!document.getElementById('imageOverlay').classList.contains('hidden')) {
                closeImage();
            }
        });

        // 点击外部关闭图片
        document.getElementById('imageOverlay').addEventListener('click', function (e) {
            if (e.target === this) closeImage();
        });

        // 添加ESC键关闭支持
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape' && !document.getElementById('imageOverlay').classList.contains('hidden')) {
                closeImage();
            }
        });

        // 修改后的closeModal函数
        function closeModal() {
            document.getElementById('modal').classList.add('hidden');
            closeImage(); // 同时关闭可能打开的图片
            document.documentElement.style.overflow = 'auto'; // 新增
            document.body.style.overflow = 'auto';
            document.getElementById('modalContent').scrollTop = 0;
        }
        function sortPapersByDate() {
            const papers = document.querySelectorAll('.card');
            const paperArray = Array.from(papers);

            // 提取日期并转换为日期对象
            paperArray.sort((a, b) => {
                const dateA = new Date(a.querySelector('.flex .fas.fa-calendar-alt + span').textContent);
                const dateB = new Date(b.querySelector('.flex .fas.fa-calendar-alt + span').textContent);
                return dateB - dateA; // 降序排序
            });

            // 重新插入到页面
            const container = document.querySelector('.grid.grid-cols-3.gap-6');
            container.innerHTML = '';
            paperArray.forEach(paper => container.appendChild(paper));
        }

        // 调用排序函数
        sortPapersByDate();
        function loadMarkdown(filePath, containerId) {
            fetch(filePath)
                .then(response => {
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    return response.text();
                })
                .then(markdown => {
                    // 使用 marked.js 渲染 Markdown 为 HTML
                    const renderedHTML = marked(markdown);

                    // 将渲染后的 HTML 插入到指定的容器中
                    document.getElementById(containerId).innerHTML = renderedHTML;
                })
                .catch(error => {
                    console.error('加载 Markdown 文件失败:', error);
                    document.getElementById(containerId).innerHTML = '<p>内容加载失败，请稍后重试。</p>';
                });
        }

        // 示例：加载 paper1.md 到页面中的某个容器
        loadMarkdown('src/markdown/paper1.md', 'markdown-container');

    </script>
</body>

</html>